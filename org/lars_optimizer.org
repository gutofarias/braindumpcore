:PROPERTIES:
:ID:       92398d83-69a8-4024-be4b-908f2cc72ac1
:END:
#+title: LARS Optimizer

Layer-wise Adaptive Rate Scaling (LARS) is a [[id:1be857e0-0197-44d1-853a-e0e5b74d1b7b][Neural Network Optimizer]]. The
technique allows [[id:1c9a7af1-fe4f-49b7-a19b-961bd125cdb8][Large Batch Training]] without significant decrease in accuracy
cite:you17_large_batch_train_convol_networ. One of the secondary goals is
[[id:b85483b8-9e57-4b6d-babf-5013f99119a0][Fast Neural Network Training]].

* Implementations
- [[https://github.com/noahgolmant/pytorch-lars][pytorch-lars]]

bibliography:biblio.bib
