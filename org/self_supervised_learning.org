:PROPERTIES:
:ID:       eecde484-c101-40f6-a099-9cf4a95b832a
:END:
#+hugo_slug: self_supervised_learning
#+title: Self-supervised Learning

[[id:70455587-806d-456a-b172-9a0f46346a18][Prediction is the Essence of Intelligence]]

* Self-supervised Learning vs Other Learning Paradigms
:PROPERTIES:
:ID:       03a42dc2-7489-4509-a478-cd1c002c53bd
:END:
In self-supervised learning, the machine predicts any part of its input for any observed part. For example, it may predict future frames in videos. This results in a lot of feedback.

In [[id:be63d7a1-322e-40df-a184-90ad2b8aabb4][Reinforcement Learning ‚≠ê]], the machine predicts a scalar reward given weak feedback once in a while. Since there is very little feedback, it seems impossible to learn any complex representations in a short amount of time.

See [[id:cc520cb6-0a5c-4944-88e4-b1c0ce4be407][LeCun's Cake Analogy]].

* Image-based

Exemplar-CNN creates surrogate training dataset with unlabeled image patches. Surrogate classes are created by applying image transformations, such as rotation.

Another class of tasks involve extracting multiple patches from a single image, and asking the model to predict the relationship between the patches.

The model can also be tasked to perform colorization: coloring a grayscale input image.

* Video-based

Any visual representation learned for the same object across close frames should be close in the latent feature space. For example, applying a triplet loss on patches of motion (compared to a random patch).

Another common task is to validate the order of frames. Training frames can be sampled from high-motion windows in order (a,b,c,d,e). Positive tuples such as (b,c,d) can be formed, and negative tuples like (b,a,d), (b,e,d) can be created.
